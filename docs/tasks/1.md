# prio
- json_type
- auth
- db reconnect
- append - pozwala na dodawanie nowych danych na końcu poprzednich, bez potrzeby wykonywania read (zmiejsza ilośc przesyłanych danych przez serwer) 

# todo
0. zrobic wersje testową na .dll i Hot reload (na początek można tak wrzucić ecoder i sprawdzić roznice w predkości działania)
1. cachowanie wartości key z conn do serwera tak aby nie brodcastować każdego req na all serwery
2. system auth
3. json_data_type
4. sql_commands
13. auto reconect

--- miej wazne ---
5. ui
6. webDav
7. fs
8. opdja włączenia jakiejś kompresji
9. zamiana zapisu w jsonie na binarke
10. opcja performance-no-limits
    > wczytanie wszystkich key do ramu żeby szybko działało
11. automatyczny backup na innym serweże
12. komendy
    + credits
        > wyświetli liste osob które przyczyniły sie do rozwoju db
        mozna np bedzie po dadaniu perms ludzi ktorzy podejma sie proby crackowania db
13. jeżeli wykonywane jest save() w objekcie z "free_block" to po oznaczeniu w pliku tego bloku jako zajętego
    > można pozwolić na asynchroniczne zapisywanie (na raz można zapisywać w środku pliku i na jego końcu.)

    > opcjonalnie można serwerów z np 4 rdzeniami mieć przygotowane 4 zarezerwowane objekty w pliku tak aby wszystkie 4 mogły na raz dodawać dane
    > i mieć 1 blokcujący się proces (mutex) który przydzielał by te wolne miejsca tak aby żadne dane nie zostały niepoprawnie nadpisane

    > zrobić test dla np 10k wartości przed i po implementacji
14. jako forme kompresji (opcjonalną):
    > dla każdego wpisu robić hasha na podstawie danych, i sprawdzać
    w pliku z hashami / cache czy już takiego nie ma, jak jest to zamiast zapisywać dane dodać tylko odwołanie
    do już zapisanych informacji.
    > jak ktoś będzie chciał edytowac wpis z odwołania to najpierw zamienic odwołanie
    na dane a dopiero potem akcja 
15. obecnie podczas dostępu do pliku jest on blokowany przez mutex.
    można blokować podczas sync save, nie blokować podczas async save
    i pozwolić read na async read dopuki dany blok nie jest w trakcie innej operacji zapisu:

    > BlockManager będzie przechowywał status w jakim miejscu wykonywany jest zapis, jeżeli zapis nie jest
    wykonywany na danym bloku można pozwolić na jego odczyt asynchronicznie

16. attach()
pozwala na dołączenie danych do danego key (zaczyna zapisywać od endPtr do data.Size()),
jeżeli nie ma miejsca to dodać jakąś formę pointera odnoszącego się do innego ptr w db a może
nawet innym pliku

17. Size
    sprawdzić obsługę działania dużych plików ( db pokroju 50GB+ )

17. 2. - sub Table:
automatyczne limitowanie wielkości pliku (po teście z 17. będzie wiadomo do jakiej wielkości pliku db jest wydajne)

package tablesManager



jeżeli plik będzie za duży to: 1. zapisać do /db/tables.gob
subtable zapisywać w db/subtables/
max_size_table: {name: "data.bin", subtable: "generated id / file name"}

jeżeli w tablesManager 

18. zrobic sesonwą licencje
19. jezeli nie ma zadnych polaczonych serwerów w Tsu network to jezeli loklanie nie ma danych, nie czekaj na odp z serwerm nawet jej nie wysyłaj
    + serwery mogą odpowiadać czymś na styl "key": no data i jak wszystkie tak odpowiedza to znaczy, że można odrazu zwrócić info że nie ma danych na serweże

20. load balancer
    > można napisać coś na styl load balancera który równomiernie rozkładał by
    polecenia zapisu pomiędzy serwery w sieci tak aby jeden serwer nie otrzymywał
    wszystkich req,
    > ewentualnie napisać biblioteki tak aby client pytał się o ip serwera
    do którego ma wysyłać dane, tak żeby +/- 50/50 rozkładać przesyłane req

--- do wymyslenia funkcje ---
1. dla time series data -> coś na styl timestamp: data (małe / średnie ilości danych ale mega dużo)

=== todo w ten weekend ===
0, 2 + stream danych + 13
